"""
Benchmarking and profiling utilities for FastVLA.
Includes memory profiling, throughput measurement, and performance comparison.
"""
import torch
import torch.nn as nn
import time
from typing import Dict, List, Optional, Any
from contextlib import contextmanager
import psutil
try:
    import GPUtil
except ImportError:
    GPUtil = None
from .optimization import estimate_memory_usage


class PerformanceProfiler:
    """
    Profile model performance including memory usage, throughput, and latency.
    """
    
    def __init__(self, device: str = "cuda"):
        self.device = device
        self.metrics = []
    
    @contextmanager
    def profile(self, name: str = "operation"):
        """
        Context manager for profiling an operation.
        
        Args:
            name: Name of the operation
        """
        # Clear cache
        if self.device == "cuda":
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
        
        # Get initial memory
        initial_memory = self.get_memory_usage()
        
        # Start timing
        start_time = time.time()
        
        try:
            yield
        finally:
            # End timing
            if self.device == "cuda":
                torch.cuda.synchronize()
            end_time = time.time()
            
            # Get final memory
            final_memory = self.get_memory_usage()
            
            # Record metrics
            metrics = {
                "name": name,
                "time": end_time - start_time,
                "initial_memory_gb": initial_memory,
                "final_memory_gb": final_memory,
                "memory_delta_gb": final_memory - initial_memory,
            }
            self.metrics.append(metrics)
    
    def get_memory_usage(self) -> float:
        """
        Get current memory usage in GB.
        
        Returns:
            Memory usage in GB
        """
        if self.device == "cuda" and torch.cuda.is_available():
            return torch.cuda.memory_allocated() / (1024 ** 3)
        else:
            process = psutil.Process()
            return process.memory_info().rss / (1024 ** 3)
    
    def get_gpu_memory(self) -> Dict[str, float]:
        """
        Get GPU memory usage.
        
        Returns:
            Dictionary with GPU memory info
        """
        if not torch.cuda.is_available():
            return {}
        
        if GPUtil is None:
            # Fallback to torch memory info
            memory_info = {}
            for i in range(torch.cuda.device_count()):
                memory_info[f"gpu_{i}"] = {
                    "memory_used_gb": torch.cuda.memory_allocated(i) / (1024 ** 3),
                    "memory_total_gb": torch.cuda.get_device_properties(i).total_memory / (1024 ** 3),
                    "memory_percent": (torch.cuda.memory_allocated(i) / torch.cuda.get_device_properties(i).total_memory) * 100,
                }
            return memory_info
        
        gpus = GPUtil.getGPUs()
        memory_info = {}
        
        for i, gpu in enumerate(gpus):
            memory_info[f"gpu_{i}"] = {
                "memory_used_gb": gpu.memoryUsed / 1024,
                "memory_total_gb": gpu.memoryTotal / 1024,
                "memory_percent": gpu.memoryUtil * 100,
            }
        
        return memory_info
    
    def benchmark_forward_pass(
        self,
        model: nn.Module,
        batch: Dict[str, torch.Tensor],
        num_iterations: int = 100,
        warmup_iterations: int = 10,
    ) -> Dict[str, float]:
        """
        Benchmark forward pass performance.
        
        Args:
            model: The model to benchmark
            batch: Input batch
            num_iterations: Number of iterations to run
            warmup_iterations: Number of warmup iterations
            
        Returns:
            Dictionary with benchmark results
        """
        model.eval()
        
        # Warmup
        with torch.no_grad():
            for _ in range(warmup_iterations):
                _ = model(**batch)
        
        if self.device == "cuda":
            torch.cuda.synchronize()
        
        # Benchmark
        times = []
        with torch.no_grad():
            for _ in range(num_iterations):
                start = time.time()
                _ = model(**batch)
                if self.device == "cuda":
                    torch.cuda.synchronize()
                end = time.time()
                times.append(end - start)
        
        avg_time = sum(times) / len(times)
        std_time = (sum((t - avg_time) ** 2 for t in times) / len(times)) ** 0.5
        
        batch_size = batch["pixel_values"].size(0) if "pixel_values" in batch else 1
        throughput = batch_size / avg_time
        
        return {
            "avg_latency_ms": avg_time * 1000,
            "std_latency_ms": std_time * 1000,
            "min_latency_ms": min(times) * 1000,
            "max_latency_ms": max(times) * 1000,
            "throughput_samples_per_sec": throughput,
            "num_iterations": num_iterations,
        }
    
    def benchmark_training_step(
        self,
        model: nn.Module,
        batch: Dict[str, torch.Tensor],
        optimizer: torch.optim.Optimizer,
        num_iterations: int = 50,
        warmup_iterations: int = 5,
    ) -> Dict[str, float]:
        """
        Benchmark training step performance.
        
        Args:
            model: The model to benchmark
            batch: Input batch
            optimizer: Optimizer
            num_iterations: Number of iterations to run
            warmup_iterations: Number of warmup iterations
            
        Returns:
            Dictionary with benchmark results
        """
        model.train()
        
        # Warmup
        for _ in range(warmup_iterations):
            optimizer.zero_grad()
            _, loss = model(**batch)
            loss.backward()
            optimizer.step()
        
        if self.device == "cuda":
            torch.cuda.synchronize()
        
        # Benchmark
        times = []
        for _ in range(num_iterations):
            start = time.time()
            optimizer.zero_grad()
            _, loss = model(**batch)
            loss.backward()
            optimizer.step()
            if self.device == "cuda":
                torch.cuda.synchronize()
            end = time.time()
            times.append(end - start)
        
        avg_time = sum(times) / len(times)
        std_time = (sum((t - avg_time) ** 2 for t in times) / len(times)) ** 0.5
        
        batch_size = batch["pixel_values"].size(0) if "pixel_values" in batch else 1
        throughput = batch_size / avg_time
        
        return {
            "avg_time_per_step_ms": avg_time * 1000,
            "std_time_per_step_ms": std_time * 1000,
            "min_time_per_step_ms": min(times) * 1000,
            "max_time_per_step_ms": max(times) * 1000,
            "throughput_samples_per_sec": throughput,
            "num_iterations": num_iterations,
        }
    
    def get_summary(self) -> Dict[str, Any]:
        """
        Get summary of all profiled operations.
        
        Returns:
            Dictionary with summary statistics
        """
        if not self.metrics:
            return {}
        
        total_time = sum(m["time"] for m in self.metrics)
        max_memory = max(m["final_memory_gb"] for m in self.metrics)
        
        return {
            "total_time_sec": total_time,
            "max_memory_gb": max_memory,
            "operations": self.metrics,
        }
    
    def reset(self):
        """Reset profiler metrics."""
        self.metrics = []


def compare_models(
    models: Dict[str, nn.Module],
    batch: Dict[str, torch.Tensor],
    num_iterations: int = 100,
) -> Dict[str, Dict[str, float]]:
    """
    Compare performance of multiple models.
    
    Args:
        models: Dictionary of model names to models
        batch: Input batch
        num_iterations: Number of iterations to run
        
    Returns:
        Dictionary with comparison results
    """
    results = {}
    profiler = PerformanceProfiler()
    
    for name, model in models.items():
        print(f"Benchmarking {name}...")
        metrics = profiler.benchmark_forward_pass(model, batch, num_iterations)
        results[name] = metrics
        profiler.reset()
    
    return results


def print_benchmark_results(results: Dict[str, Dict[str, float]]):
    """
    Print benchmark results in a formatted table.
    
    Args:
        results: Dictionary with benchmark results
    """
    print("\n" + "=" * 80)
    print("BENCHMARK RESULTS")
    print("=" * 80)
    
    for name, metrics in results.items():
        print(f"\n{name}:")
        print(f"  Average Latency: {metrics.get('avg_latency_ms', 0):.2f} ms")
        print(f"  Throughput: {metrics.get('throughput_samples_per_sec', 0):.2f} samples/sec")
        if 'avg_time_per_step_ms' in metrics:
            print(f"  Time per Step: {metrics.get('avg_time_per_step_ms', 0):.2f} ms")
    
    print("=" * 80)

